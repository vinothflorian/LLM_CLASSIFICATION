{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f19390c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VINOTH\\AppData\\Local\\Temp\\ipykernel_10288\\966064847.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x['consolidated'] = \"Prompt: \" + x['prompt'] + \"response_a: \" + x['response_a'] + \"response_b: \" + x['response_b']\n",
      "C:\\Users\\VINOTH\\AppData\\Local\\Temp\\ipykernel_10288\\966064847.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop(columns=['prompt', 'response_a', 'response_b'], inplace = True)\n",
      "C:\\Users\\VINOTH\\AppData\\Local\\Temp\\ipykernel_10288\\966064847.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[i] = x[i].apply(embd_vector)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tokens = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "model_sen = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def embd_vector1(x):\n",
    "    tok_id = tokens(x, padding = True, truncation = True, return_tensors = 'pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**tok_id)\n",
    "    \n",
    "   # las_embed = output.last_hidden_state\n",
    "    #cls_embeddings = las_embed[:, 0, :] \n",
    "\n",
    "    #vec = model(**tok_id).last_hidden_item\n",
    "    return output.last_hidden_state.mean(dim=1).squeeze().tolist()\n",
    "\n",
    "def embd_vector(text):\n",
    "    return model_sen.encode(text, convert_to_numpy=True).tolist()\n",
    "\n",
    "\n",
    "def join_text(lt):\n",
    "    return \" \".join(lt)\n",
    "\n",
    "\n",
    "DF_SOURCE1 = pd.read_csv(r\"D:\\PYTHON\\LLM_CLASSIFICATION_KAGGLE\\Dataset\\llm-classification-finetuning\\train.csv\")\n",
    "\n",
    "def DF_Preprocess(DF_SOURCE):\n",
    "\n",
    "\n",
    "    x = DF_SOURCE[['prompt', 'response_a', 'response_b']]\n",
    "\n",
    "\n",
    "    x['consolidated'] = \"Prompt: \" + x['prompt'] + \"response_a: \" + x['response_a'] + \"response_b: \" + x['response_b']\n",
    "\n",
    "\n",
    "    x.drop(columns=['prompt', 'response_a', 'response_b'], inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "    y = torch.tensor(DF_SOURCE[['winner_model_a', 'winner_model_b', 'winner_tie']].values)\n",
    "    y = torch.argmax(y, dim=1).tolist()\n",
    "    y_df = pd.DataFrame(y)\n",
    "    for i in x.columns:\n",
    "        x[i] = x[i].apply(embd_vector)\n",
    "        \n",
    "\n",
    "\n",
    "    DF_EVAL = pd.concat([x,y_df], axis=1)\n",
    "    DF_EVAL.rename(columns={0 : \"Actual\"}, inplace= True)\n",
    "    return DF_EVAL\n",
    "\n",
    "DF_EVAL =  DF_Preprocess(DF_SOURCE1)\n",
    "DF_EVAL.to_csv(\"Embed_train.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b11141d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\VINOTH\\AppData\\Local\\Temp\\ipykernel_28432\\3757302788.py:10: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  DF_TRAIN = pd.read_csv(\"D:\\PYTHON\\LLM_CLASSIFICATION_KAGGLE\\Embed_train.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'consolidated', 'Actual'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025669</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>-0.038254</td>\n",
       "      <td>0.014313</td>\n",
       "      <td>-0.040225</td>\n",
       "      <td>0.065503</td>\n",
       "      <td>-0.036204</td>\n",
       "      <td>-0.058132</td>\n",
       "      <td>-0.046955</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018506</td>\n",
       "      <td>0.032707</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>-0.009779</td>\n",
       "      <td>-0.037301</td>\n",
       "      <td>0.042187</td>\n",
       "      <td>0.095915</td>\n",
       "      <td>0.005455</td>\n",
       "      <td>-0.050981</td>\n",
       "      <td>-0.029615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006360</td>\n",
       "      <td>0.059760</td>\n",
       "      <td>0.023489</td>\n",
       "      <td>0.023992</td>\n",
       "      <td>-0.085984</td>\n",
       "      <td>0.091230</td>\n",
       "      <td>0.020206</td>\n",
       "      <td>-0.004656</td>\n",
       "      <td>0.069498</td>\n",
       "      <td>-0.040986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100965</td>\n",
       "      <td>0.068610</td>\n",
       "      <td>0.082808</td>\n",
       "      <td>0.010535</td>\n",
       "      <td>0.062725</td>\n",
       "      <td>0.085089</td>\n",
       "      <td>-0.014561</td>\n",
       "      <td>0.077452</td>\n",
       "      <td>0.020137</td>\n",
       "      <td>-0.017614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.085274</td>\n",
       "      <td>0.036727</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>-0.010576</td>\n",
       "      <td>-0.138973</td>\n",
       "      <td>-0.127312</td>\n",
       "      <td>0.059594</td>\n",
       "      <td>0.111553</td>\n",
       "      <td>0.010960</td>\n",
       "      <td>-0.033244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003343</td>\n",
       "      <td>0.069076</td>\n",
       "      <td>-0.033395</td>\n",
       "      <td>-0.019938</td>\n",
       "      <td>-0.006622</td>\n",
       "      <td>0.079040</td>\n",
       "      <td>-0.003298</td>\n",
       "      <td>0.159203</td>\n",
       "      <td>0.083756</td>\n",
       "      <td>-0.055680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.068364</td>\n",
       "      <td>-0.020779</td>\n",
       "      <td>-0.043004</td>\n",
       "      <td>0.027835</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>-0.024870</td>\n",
       "      <td>-0.019578</td>\n",
       "      <td>0.024570</td>\n",
       "      <td>-0.050910</td>\n",
       "      <td>-0.064350</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030212</td>\n",
       "      <td>0.054888</td>\n",
       "      <td>0.013891</td>\n",
       "      <td>-0.004943</td>\n",
       "      <td>-0.023017</td>\n",
       "      <td>0.020383</td>\n",
       "      <td>0.176729</td>\n",
       "      <td>0.080034</td>\n",
       "      <td>-0.096659</td>\n",
       "      <td>0.030012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.084832</td>\n",
       "      <td>0.114480</td>\n",
       "      <td>0.017523</td>\n",
       "      <td>-0.043089</td>\n",
       "      <td>-0.062486</td>\n",
       "      <td>-0.011723</td>\n",
       "      <td>0.072811</td>\n",
       "      <td>0.042801</td>\n",
       "      <td>-0.048233</td>\n",
       "      <td>0.058617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057627</td>\n",
       "      <td>0.012610</td>\n",
       "      <td>-0.094707</td>\n",
       "      <td>-0.113518</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.133359</td>\n",
       "      <td>0.074227</td>\n",
       "      <td>0.009441</td>\n",
       "      <td>-0.094240</td>\n",
       "      <td>-0.048816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.025669  0.005369 -0.038254  0.014313 -0.040225  0.065503 -0.036204   \n",
       "1 -0.006360  0.059760  0.023489  0.023992 -0.085984  0.091230  0.020206   \n",
       "2 -0.085274  0.036727  0.002647 -0.010576 -0.138973 -0.127312  0.059594   \n",
       "3 -0.068364 -0.020779 -0.043004  0.027835  0.000839 -0.024870 -0.019578   \n",
       "4  0.084832  0.114480  0.017523 -0.043089 -0.062486 -0.011723  0.072811   \n",
       "\n",
       "        7         8         9    ...       374       375       376       377  \\\n",
       "0 -0.058132 -0.046955 -0.000286  ... -0.018506  0.032707  0.006812 -0.009779   \n",
       "1 -0.004656  0.069498 -0.040986  ... -0.100965  0.068610  0.082808  0.010535   \n",
       "2  0.111553  0.010960 -0.033244  ... -0.003343  0.069076 -0.033395 -0.019938   \n",
       "3  0.024570 -0.050910 -0.064350  ... -0.030212  0.054888  0.013891 -0.004943   \n",
       "4  0.042801 -0.048233  0.058617  ...  0.057627  0.012610 -0.094707 -0.113518   \n",
       "\n",
       "        378       379       380       381       382       383  \n",
       "0 -0.037301  0.042187  0.095915  0.005455 -0.050981 -0.029615  \n",
       "1  0.062725  0.085089 -0.014561  0.077452  0.020137 -0.017614  \n",
       "2 -0.006622  0.079040 -0.003298  0.159203  0.083756 -0.055680  \n",
       "3 -0.023017  0.020383  0.176729  0.080034 -0.096659  0.030012  \n",
       "4  0.001864  0.133359  0.074227  0.009441 -0.094240 -0.048816  \n",
       "\n",
       "[5 rows x 384 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "\n",
    "DF_TRAIN = pd.read_csv(\"D:\\PYTHON\\LLM_CLASSIFICATION_KAGGLE\\Embed_train.csv\")\n",
    "\n",
    "print(DF_TRAIN.columns)\n",
    "\n",
    "DF_TRAIN['consolidated'] = DF_TRAIN['consolidated'].apply(ast.literal_eval)\n",
    "\n",
    "DF_IND = pd.DataFrame(DF_TRAIN['consolidated'].to_list())\n",
    "\n",
    "DF_IND.to_csv(\"df_ind.csv\")\n",
    "\n",
    "DF_IND.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68be91d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025669</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>-0.038254</td>\n",
       "      <td>0.014313</td>\n",
       "      <td>-0.040225</td>\n",
       "      <td>0.065503</td>\n",
       "      <td>-0.036204</td>\n",
       "      <td>-0.058132</td>\n",
       "      <td>-0.046955</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032707</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>-0.009779</td>\n",
       "      <td>-0.037301</td>\n",
       "      <td>0.042187</td>\n",
       "      <td>0.095915</td>\n",
       "      <td>0.005455</td>\n",
       "      <td>-0.050981</td>\n",
       "      <td>-0.029615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006360</td>\n",
       "      <td>0.059760</td>\n",
       "      <td>0.023489</td>\n",
       "      <td>0.023992</td>\n",
       "      <td>-0.085984</td>\n",
       "      <td>0.091230</td>\n",
       "      <td>0.020206</td>\n",
       "      <td>-0.004656</td>\n",
       "      <td>0.069498</td>\n",
       "      <td>-0.040986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068610</td>\n",
       "      <td>0.082808</td>\n",
       "      <td>0.010535</td>\n",
       "      <td>0.062725</td>\n",
       "      <td>0.085089</td>\n",
       "      <td>-0.014561</td>\n",
       "      <td>0.077452</td>\n",
       "      <td>0.020137</td>\n",
       "      <td>-0.017614</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.085274</td>\n",
       "      <td>0.036727</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>-0.010576</td>\n",
       "      <td>-0.138973</td>\n",
       "      <td>-0.127312</td>\n",
       "      <td>0.059594</td>\n",
       "      <td>0.111553</td>\n",
       "      <td>0.010960</td>\n",
       "      <td>-0.033244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069076</td>\n",
       "      <td>-0.033395</td>\n",
       "      <td>-0.019938</td>\n",
       "      <td>-0.006622</td>\n",
       "      <td>0.079040</td>\n",
       "      <td>-0.003298</td>\n",
       "      <td>0.159203</td>\n",
       "      <td>0.083756</td>\n",
       "      <td>-0.055680</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.068364</td>\n",
       "      <td>-0.020779</td>\n",
       "      <td>-0.043004</td>\n",
       "      <td>0.027835</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>-0.024870</td>\n",
       "      <td>-0.019578</td>\n",
       "      <td>0.024570</td>\n",
       "      <td>-0.050910</td>\n",
       "      <td>-0.064350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054888</td>\n",
       "      <td>0.013891</td>\n",
       "      <td>-0.004943</td>\n",
       "      <td>-0.023017</td>\n",
       "      <td>0.020383</td>\n",
       "      <td>0.176729</td>\n",
       "      <td>0.080034</td>\n",
       "      <td>-0.096659</td>\n",
       "      <td>0.030012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.084832</td>\n",
       "      <td>0.114480</td>\n",
       "      <td>0.017523</td>\n",
       "      <td>-0.043089</td>\n",
       "      <td>-0.062486</td>\n",
       "      <td>-0.011723</td>\n",
       "      <td>0.072811</td>\n",
       "      <td>0.042801</td>\n",
       "      <td>-0.048233</td>\n",
       "      <td>0.058617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012610</td>\n",
       "      <td>-0.094707</td>\n",
       "      <td>-0.113518</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.133359</td>\n",
       "      <td>0.074227</td>\n",
       "      <td>0.009441</td>\n",
       "      <td>-0.094240</td>\n",
       "      <td>-0.048816</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.025669  0.005369 -0.038254  0.014313 -0.040225  0.065503 -0.036204   \n",
       "1 -0.006360  0.059760  0.023489  0.023992 -0.085984  0.091230  0.020206   \n",
       "2 -0.085274  0.036727  0.002647 -0.010576 -0.138973 -0.127312  0.059594   \n",
       "3 -0.068364 -0.020779 -0.043004  0.027835  0.000839 -0.024870 -0.019578   \n",
       "4  0.084832  0.114480  0.017523 -0.043089 -0.062486 -0.011723  0.072811   \n",
       "\n",
       "          7         8         9  ...       375       376       377       378  \\\n",
       "0 -0.058132 -0.046955 -0.000286  ...  0.032707  0.006812 -0.009779 -0.037301   \n",
       "1 -0.004656  0.069498 -0.040986  ...  0.068610  0.082808  0.010535  0.062725   \n",
       "2  0.111553  0.010960 -0.033244  ...  0.069076 -0.033395 -0.019938 -0.006622   \n",
       "3  0.024570 -0.050910 -0.064350  ...  0.054888  0.013891 -0.004943 -0.023017   \n",
       "4  0.042801 -0.048233  0.058617  ...  0.012610 -0.094707 -0.113518  0.001864   \n",
       "\n",
       "        379       380       381       382       383  Actual  \n",
       "0  0.042187  0.095915  0.005455 -0.050981 -0.029615       0  \n",
       "1  0.085089 -0.014561  0.077452  0.020137 -0.017614       1  \n",
       "2  0.079040 -0.003298  0.159203  0.083756 -0.055680       2  \n",
       "3  0.020383  0.176729  0.080034 -0.096659  0.030012       0  \n",
       "4  0.133359  0.074227  0.009441 -0.094240 -0.048816       1  \n",
       "\n",
       "[5 rows x 385 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_IND['Actual'] = DF_TRAIN['Actual']\n",
    "DF_IND.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcabceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report train:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.76      0.83     19415\n",
      "           1       0.89      0.84      0.86     16537\n",
      "           2       0.57      0.81      0.67     10029\n",
      "\n",
      "    accuracy                           0.80     45981\n",
      "   macro avg       0.79      0.80      0.79     45981\n",
      "weighted avg       0.83      0.80      0.81     45981\n",
      "\n",
      "classification report test:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.37      0.43      5559\n",
      "           1       0.35      0.36      0.35      3814\n",
      "           2       0.28      0.47      0.35      2123\n",
      "\n",
      "    accuracy                           0.38     11496\n",
      "   macro avg       0.38      0.40      0.38     11496\n",
      "weighted avg       0.41      0.38      0.39     11496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def measure(x,y):\n",
    "    print(f\"classification report:  {classification_report(x,y)}\" )\n",
    "    print(f\"confusion_matrix report:  {confusion_matrix(x,y)}\" )\n",
    "    print(f\"F1_score : {f1_score(x,y)}\")\n",
    "\n",
    "\n",
    "x_trad = DF_IND.drop(columns=['Actual'])\n",
    "y_trad = DF_IND['Actual']\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_trad, y_trad, test_size=0.3, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "prd_train = model.predict(x_train)\n",
    "prd_test = model.predict(x_test)\n",
    "prd_train_prob = model.predict_proba(x_train)\n",
    "\n",
    "\n",
    "print(f\"classification report train:  {classification_report(prd_train,y_train)}\")\n",
    "\n",
    "print(f\"classification report test:  {classification_report(prd_test,y_test)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1095cdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report train:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.41      0.43     15708\n",
      "           1       0.40      0.41      0.41     13601\n",
      "           2       0.38      0.43      0.40     10924\n",
      "\n",
      "    accuracy                           0.41     40233\n",
      "   macro avg       0.41      0.42      0.41     40233\n",
      "weighted avg       0.42      0.41      0.42     40233\n",
      "\n",
      "classification report test:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.38      0.40      6739\n",
      "           1       0.36      0.37      0.36      5744\n",
      "           2       0.37      0.41      0.39      4761\n",
      "\n",
      "    accuracy                           0.39     17244\n",
      "   macro avg       0.38      0.39      0.38     17244\n",
      "weighted avg       0.39      0.39      0.39     17244\n",
      "\n",
      "f1_score train: 0.4131778806961767\n",
      "f1_score test: 0.38493772208305604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def measure(x,y):\n",
    "    print(f\"classification report:  {classification_report(x,y)}\" )\n",
    "    print(f\"confusion_matrix report:  {confusion_matrix(x,y)}\" )\n",
    "    print(f\"F1_score : {f1_score(x,y)}\")\n",
    "\n",
    "\n",
    "x_trad = DF_IND.drop(columns=['Actual'])\n",
    "y_trad = DF_IND['Actual']\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_trad, y_trad, test_size=0.3, random_state=42)\n",
    "\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(x_train, y_train)\n",
    "prd_train = model1.predict(x_train)\n",
    "prd_test = model1.predict(x_test)\n",
    "prd_train_prob = model1.predict_proba(x_train)\n",
    "\n",
    "\n",
    "print(f\"classification report train:  {classification_report(prd_train,y_train)}\")\n",
    "\n",
    "print(f\"classification report test:  {classification_report(prd_test,y_test)}\")\n",
    "\n",
    "print(f\"f1_score train: {f1_score(prd_train,y_train, average='macro')}\")\n",
    "print(f\"f1_score test: {f1_score(prd_test,y_test, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3927da43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report train:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     14102\n",
      "           1       0.99      0.99      0.99     13715\n",
      "           2       0.99      0.99      0.99     12416\n",
      "\n",
      "    accuracy                           0.99     40233\n",
      "   macro avg       0.99      0.99      0.99     40233\n",
      "weighted avg       0.99      0.99      0.99     40233\n",
      "\n",
      "classification report test:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.36      0.36      6053\n",
      "           1       0.36      0.35      0.35      5927\n",
      "           2       0.34      0.34      0.34      5264\n",
      "\n",
      "    accuracy                           0.35     17244\n",
      "   macro avg       0.35      0.35      0.35     17244\n",
      "weighted avg       0.35      0.35      0.35     17244\n",
      "\n",
      "f1_score train: 0.9914568146451465\n",
      "f1_score test: 0.35061681544310835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def measure(x,y):\n",
    "    print(f\"classification report:  {classification_report(x,y)}\" )\n",
    "    print(f\"confusion_matrix report:  {confusion_matrix(x,y)}\" )\n",
    "    print(f\"F1_score : {f1_score(x,y)}\")\n",
    "\n",
    "\n",
    "x_trad = DF_IND.drop(columns=['Actual'])\n",
    "y_trad = DF_IND['Actual']\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_trad, y_trad, test_size=0.3, random_state=42)\n",
    "\n",
    "model1 = DecisionTreeClassifier()\n",
    "model1.fit(x_train, y_train)\n",
    "prd_train = model1.predict(x_train)\n",
    "prd_test = model1.predict(x_test)\n",
    "prd_train_prob = model1.predict_proba(x_train)\n",
    "\n",
    "\n",
    "print(f\"classification report train:  {classification_report(prd_train,y_train)}\")\n",
    "\n",
    "print(f\"classification report test:  {classification_report(prd_test,y_test)}\")\n",
    "\n",
    "print(f\"f1_score train: {f1_score(prd_train,y_train, average='macro')}\")\n",
    "print(f\"f1_score test: {f1_score(prd_test,y_test, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "734c0c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 135 candidates, totalling 675 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VINOTH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\ma\\core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Classification Report (Train):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.55      0.45     13997\n",
      "           1       0.38      0.30      0.34     13796\n",
      "           2       0.41      0.31      0.35     12440\n",
      "\n",
      "    accuracy                           0.39     40233\n",
      "   macro avg       0.39      0.39      0.38     40233\n",
      "weighted avg       0.39      0.39      0.38     40233\n",
      "\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.52      0.43      6067\n",
      "           1       0.35      0.28      0.31      5856\n",
      "           2       0.38      0.30      0.33      5321\n",
      "\n",
      "    accuracy                           0.37     17244\n",
      "   macro avg       0.37      0.36      0.36     17244\n",
      "weighted avg       0.37      0.37      0.36     17244\n",
      "\n",
      "F1 Score (Train): 0.38087363816009295\n",
      "F1 Score (Test): 0.3591380357354195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [None, 5, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize base model\n",
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=dtree,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='f1_macro',\n",
    "                           cv=5,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "prd_train = best_model.predict(x_train)\n",
    "prd_test = best_model.predict(x_test)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"\\nBest Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Classification Report (Train):\\n{classification_report(y_train, prd_train)}\")\n",
    "print(f\"Classification Report (Test):\\n{classification_report(y_test, prd_test)}\")\n",
    "print(f\"F1 Score (Train): {f1_score(y_train, prd_train, average='macro')}\")\n",
    "print(f\"F1 Score (Test): {f1_score(y_test, prd_test, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f59f2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0152,  0.0427,  0.0751,  ...,  0.0516,  0.0212,  0.0478],\n",
       "        [-0.0377,  0.0261, -0.0587,  ...,  0.1451, -0.0388,  0.0232],\n",
       "        [-0.0167,  0.0114, -0.0353,  ...,  0.0840, -0.0945,  0.0359],\n",
       "        ...,\n",
       "        [ 0.0478, -0.0097,  0.0756,  ..., -0.0612, -0.0925, -0.0035],\n",
       "        [-0.0745,  0.0543, -0.0065,  ..., -0.0451, -0.0848,  0.0053],\n",
       "        [-0.0362,  0.0067,  0.0308,  ...,  0.1293, -0.1251, -0.0109]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef66296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import ast\n",
    "\n",
    "DF_NN = pd.read_csv(r\"D:\\PYTHON\\LLM_CLASSIFICATION_KAGGLE\\Embed_train.csv\")\n",
    "DF_NN[\"consolidated\"] = DF_NN['consolidated'].apply(ast.literal_eval)\n",
    "DF_NN_SPLIT = pd.DataFrame(DF_NN[\"consolidated\"].values.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "573860e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0  1.062108 -0.478341 -0.768869  0.570151 -0.764261  1.351149 -1.565243   \n",
      "1  0.375476  0.547580  0.507316  0.791795 -1.665290  1.910902 -0.500860   \n",
      "2 -1.316271  0.113138  0.076527  0.000162 -2.708699 -2.843962  0.242341   \n",
      "3 -0.953757 -0.971526 -0.867068  0.879823  0.044311 -0.615116 -1.251534   \n",
      "4  2.330442  1.579696  0.384004 -0.744421 -1.202598 -0.329069  0.491719   \n",
      "\n",
      "          7         8         9  ...       375       376       377       378  \\\n",
      "0 -1.955132 -0.515351  0.119071  ...  0.219746  0.324032 -0.343080 -0.795688   \n",
      "1 -0.814805  1.919156 -0.796727  ...  0.945445  2.042512  0.043316  1.329470   \n",
      "2  1.663213  0.695383 -0.622522  ...  0.954848 -0.585170 -0.536318 -0.143887   \n",
      "3 -0.191594 -0.598018 -1.322426  ...  0.668072  0.484109 -0.251096 -0.492214   \n",
      "4  0.197162 -0.542063  1.444441  ... -0.186465 -1.971621 -2.316373  0.036407   \n",
      "\n",
      "        379       380       381       382       383    Actual  \n",
      "0  0.227874  0.683765 -0.983138 -0.445667 -0.659163 -1.184754  \n",
      "1  1.095554 -1.289306  0.314781  0.975456 -0.366765  0.049452  \n",
      "2  0.973218 -1.088152  1.788548  2.246722 -1.294213  1.283659  \n",
      "3 -0.213114  2.127094  0.361323 -1.358424  0.793639 -1.184754  \n",
      "4  2.071820  0.296430 -0.911280 -1.310091 -1.126976  0.049452  \n",
      "\n",
      "[5 rows x 385 columns]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "DF_NN_SPLIT.columns = DF_NN_SPLIT.columns.astype(str)\n",
    "\n",
    "scaler_array = scaler.fit_transform(DF_NN_SPLIT) \n",
    "\n",
    "DF_NN_SPLIT_1 = pd.DataFrame(scaler_array, columns=DF_NN_SPLIT.columns)\n",
    "\n",
    "print(DF_NN_SPLIT_1.head())\n",
    "\n",
    "DF_NN_SPLIT_1['Actual'] = DF_NN['Actual']\n",
    "X_NN = DF_NN_SPLIT_1.drop(['Actual'], axis=1)\n",
    "Y_NN = DF_NN_SPLIT_1['Actual']\n",
    "\n",
    "X_NN_TENSOR = torch.tensor(X_NN.values, dtype= torch.float32)\n",
    "Y_NN_TENSOR = torch.tensor(Y_NN.values, dtype= torch.long)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49f58c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "Dataset = TensorDataset(X_NN_TENSOR, Y_NN_TENSOR)\n",
    "Dataloader = DataLoader(Dataset, batch_size = 32, shuffle = True)\n",
    "print(X_NN_TENSOR.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d9fa4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 1.1236, Accuracy = 0.3778\n",
      "Epoch 2: Loss = 1.0113, Accuracy = 0.3975\n",
      "Epoch 3: Loss = 1.0462, Accuracy = 0.4125\n",
      "Epoch 4: Loss = 1.0714, Accuracy = 0.4304\n",
      "Epoch 5: Loss = 1.1270, Accuracy = 0.4499\n",
      "Epoch 6: Loss = 0.9436, Accuracy = 0.4786\n",
      "Epoch 7: Loss = 0.8110, Accuracy = 0.5092\n",
      "Epoch 8: Loss = 0.8462, Accuracy = 0.5402\n",
      "Epoch 9: Loss = 0.5772, Accuracy = 0.5711\n",
      "Epoch 10: Loss = 0.4837, Accuracy = 0.5999\n",
      "Epoch 11: Loss = 1.5735, Accuracy = 0.6234\n",
      "Epoch 12: Loss = 0.5984, Accuracy = 0.6488\n",
      "Epoch 13: Loss = 0.4488, Accuracy = 0.6692\n",
      "Epoch 14: Loss = 1.2967, Accuracy = 0.6868\n",
      "Epoch 15: Loss = 0.7547, Accuracy = 0.7014\n",
      "Epoch 16: Loss = 0.7344, Accuracy = 0.7198\n",
      "Epoch 17: Loss = 0.7666, Accuracy = 0.7335\n",
      "Epoch 18: Loss = 0.2154, Accuracy = 0.7456\n",
      "Epoch 19: Loss = 0.3769, Accuracy = 0.7567\n",
      "Epoch 20: Loss = 0.6123, Accuracy = 0.7659\n",
      "Epoch 21: Loss = 0.7606, Accuracy = 0.7746\n",
      "Epoch 22: Loss = 0.2201, Accuracy = 0.7857\n",
      "Epoch 23: Loss = 0.4476, Accuracy = 0.7922\n",
      "Epoch 24: Loss = 0.7141, Accuracy = 0.8001\n",
      "Epoch 25: Loss = 0.3916, Accuracy = 0.8071\n",
      "Epoch 26: Loss = 0.7300, Accuracy = 0.8151\n",
      "Epoch 27: Loss = 0.5169, Accuracy = 0.8163\n",
      "Epoch 28: Loss = 0.7919, Accuracy = 0.8265\n",
      "Epoch 29: Loss = 0.3654, Accuracy = 0.8292\n",
      "Epoch 30: Loss = 0.1881, Accuracy = 0.8344\n",
      "Epoch 31: Loss = 0.0799, Accuracy = 0.8393\n",
      "Epoch 32: Loss = 0.6842, Accuracy = 0.8440\n",
      "Epoch 33: Loss = 0.5694, Accuracy = 0.8486\n",
      "Epoch 34: Loss = 0.4411, Accuracy = 0.8532\n",
      "Epoch 35: Loss = 0.0690, Accuracy = 0.8566\n",
      "Epoch 36: Loss = 0.4051, Accuracy = 0.8578\n",
      "Epoch 37: Loss = 0.2326, Accuracy = 0.8649\n",
      "Epoch 38: Loss = 0.2692, Accuracy = 0.8662\n",
      "Epoch 39: Loss = 0.0304, Accuracy = 0.8710\n",
      "Epoch 40: Loss = 0.4203, Accuracy = 0.8727\n",
      "Epoch 41: Loss = 0.0345, Accuracy = 0.8776\n",
      "Epoch 42: Loss = 0.1461, Accuracy = 0.8768\n",
      "Epoch 43: Loss = 0.2437, Accuracy = 0.8837\n",
      "Epoch 44: Loss = 0.1340, Accuracy = 0.8840\n",
      "Epoch 45: Loss = 0.4627, Accuracy = 0.8893\n",
      "Model saved to llmnn_model.pth\n"
     ]
    }
   ],
   "source": [
    "class llmnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(llmnn, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_NN_TENSOR.shape[1], 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 16)\n",
    "        self.fc4 = nn.Linear(16, 3)\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "module = llmnn()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(module.parameters(),  lr=0.001)\n",
    "\n",
    "for epoch in range(45):\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    for x,y in Dataloader:\n",
    "        opt.zero_grad()\n",
    "        output = module(x)\n",
    "        loss = loss_fn(output,y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        prd = torch.argmax(output,dim=1)\n",
    "        total_loss += loss.item() \n",
    "        correct += (prd==y).sum().item()\n",
    "\n",
    "    acc = correct / len(Dataloader.dataset)\n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss:.4f}, Accuracy = {acc:.4f}\")\n",
    "\n",
    "torch.save(module.state_dict(), \"llmnn_model.pth\")\n",
    "print(\"Model saved to llmnn_model.pth\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6063eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_sen = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def embd_vector(text):\n",
    "    return model_sen.encode(text, convert_to_numpy=True).tolist()\n",
    "\n",
    "\n",
    "def DF_Preprocess1(DF_SOURCE):\n",
    "\n",
    "\n",
    "    x = DF_SOURCE[['prompt', 'response_a', 'response_b']]\n",
    "\n",
    "\n",
    "    x['consolidated'] = \"Prompt: \" + x['prompt'] + \"response_a: \" + x['response_a'] + \"response_b: \" + x['response_b']\n",
    "\n",
    "\n",
    "    x.drop(columns=['prompt', 'response_a', 'response_b'], inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    for i in x.columns:\n",
    "        x[i] = x[i].apply(embd_vector)\n",
    "\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33fa2f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consolidated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0434182733297348, 0.1418384164571762, 3.547...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.010802901349961758, 0.04609622061252594, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.04522497206926346, -0.08193384110927582, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        consolidated\n",
       "0  [0.0434182733297348, 0.1418384164571762, 3.547...\n",
       "1  [-0.010802901349961758, 0.04609622061252594, -...\n",
       "2  [-0.04522497206926346, -0.08193384110927582, 0..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_TEST_EVAL = pd.read_csv(r\"D:\\PYTHON\\LLM_CLASSIFICATION_KAGGLE\\Dataset\\llm-classification-finetuning\\test.csv\")\n",
    "\n",
    "DF_TEST_EVAL\n",
    "#DF_TEST_EMBED = DF_TEST_EVAL.drop( columns = ['winner_model_a', 'winner_model_b', 'winner_tie'])\n",
    "\n",
    "DF_TEST_EMBED = DF_Preprocess1(DF_TEST_EVAL)\n",
    "DF_TEST_EMBED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "653fce55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2560, 0.7430, 0.0010],\n",
      "        [0.0215, 0.3575, 0.6210],\n",
      "        [0.2135, 0.7328, 0.0537]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VINOTH\\AppData\\Local\\Temp\\ipykernel_31424\\2264010219.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predicted_class = nn.functional.softmax(output)\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "DF_TEST = pd.DataFrame(DF_TEST_EMBED[\"consolidated\"].values.tolist())\n",
    "\n",
    "DF_TEST.columns = DF_TEST.columns.astype(str)\n",
    "\n",
    "scaler_array_test = scaler.fit_transform(DF_TEST) \n",
    "\n",
    "DF_TEST1 = pd.DataFrame(scaler_array_test, columns=DF_TEST.columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_test = torch.tensor(DF_TEST1.values, dtype= torch.float32)\n",
    "module.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = module(X_test)\n",
    "    predicted_class = nn.functional.softmax(output)\n",
    "    print(predicted_class)\n",
    "\n",
    "\n",
    "DF_TEST_Y = pd.DataFrame(predicted_class, columns=['winner_model_a', 'winner_model_b', 'winner_tie'])\n",
    "DF_TEST_Y [\"id\"] = DF_TEST_EVAL[\"id\"]\n",
    "cols = ['id'] + [col for col in DF_TEST_Y.columns if col != 'id']\n",
    "DF_TEST_Y1 = DF_TEST_Y[cols]\n",
    "DF_TEST_Y1.to_csv(\"submit.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46396e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
